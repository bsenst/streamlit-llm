# streamlit-llm

## Architecture

Streamlit caching
Prompt chaining with LangChain

## Run the app

`streamlit run Main.py`

## Data source

https://synthetichealth.github.io

## Reading list

* https://streamlit.io/community/llm-hackathon-2023
* https://discuss.streamlit.io/t/streamlit-llm-hackathon/50618

## Evaluation criteria

* Inventive
* Error-free
* Public repo
* Hosted on community cloud
* Tools: LangChain, Clarifai, ...
* LLM pain points: transparency, trust, accuracy, privacy, cost reduction, ethics

## Learning resources
